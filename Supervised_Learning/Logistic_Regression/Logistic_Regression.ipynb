{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Logistic Regression\n",
    "#### Author: Zheyi Wang\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "- Introduction\n",
    "- Algorithm\n",
    "    - Model\n",
    "    - Cross-entropy\n",
    "    - Gradient Descent in Solving Logistic Regression\n",
    "- Illustration\n",
    "- Pros and Cons\n",
    "    - Pros\n",
    "    - Cons\n",
    "- Code and Application of Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction <a class=\"anchor\" id=\"Introduction\"></a>\n",
    "\n",
    "In statistics, the [logistic regression model](https://en.wikipedia.org/wiki/Logistic_regression) is used to model the probability of a certain class or event existing. This can be extended to model several classes of events. Basicly it's an extension of linear regression to deal with classification tasks.\n",
    "\n",
    "Logistic regression is used in various fields, including machine learning, most medical fields, and social sciences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm <a class=\"anchor\" id=\"Algorithm\"></a>\n",
    "\n",
    "#### Model <a class=\"anchor\" id=\"Model\"></a>\n",
    "Consider a model with two predictors, $x_1$ and $x_2$, and one binary (Bernoulli) response variable $y$, with parameter $p=P(Y=1)$. We assume a linear relationship between the predictor variables and the log-odds (also called logit) of the event that $y=1$. This linear relationship can be written in the following mathematical form :\n",
    "\n",
    "$$\\log \\frac{p}{1-p} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2$$\n",
    "\n",
    "where $\\beta_i$ are parameters of the model.\n",
    "\n",
    "We can recover the odds by exponentiating both sides of the above:\n",
    "\n",
    "$$\\frac{p}{1-p} = e^{\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2}$$\n",
    "\n",
    "Isolating $p$ we have that the probability that $y=1$ is\n",
    "\n",
    "$$p = \\frac{e^{\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2}}{e^{\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2} + 1} = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2)}} = \\sigma(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2)$$\n",
    "\n",
    "where $\\sigma(\\cdot)$ is the sigmoid function.\n",
    "\n",
    "\n",
    "#### Cross-entropy <a class=\"anchor\" id=\"Cross-entropy\"></a>\n",
    "Cross-entropy loss is widely used in classification tasks. The [cross-entropy](https://en.wikipedia.org/wiki/Cross_entropy) between two probability distributions $p$ and $q$ over the same underlying set of events measures the average number of bits needed to identify an event drawn from the set if a coding scheme used for the set is optimized for an estimated probability distribution $q$, rather than the true distribution $p$.\n",
    "\n",
    "For discrete probability distributions, it's given by\n",
    "$$\n",
    "L(p, q) = -\\sum_x {p(x)log (q(x))}\n",
    "$$\n",
    "\n",
    "And for binary classification, the form is\n",
    "$$\n",
    "L(p) = - (y log(p) + (1-y)log(1-p))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent in Solving Logistic Regression <a class=\"anchor\" id=\"Gradient\"></a>\n",
    "\n",
    "To use gradient descent to solve the solution of Logistic Regression, similar with linear regression, we take the derivative of loss function, and update the weights by the algorithm in the **Gradient Descent** section.\n",
    "\n",
    "The loss function is the different part. Here the loss function for binary classification is given by\n",
    "$$\n",
    "L(\\hat{y}, y) = - (y log(\\sigma(\\mathbf{x}\\boldsymbol{\\beta})) + (1-y)log(1-\\sigma(\\mathbf{x}\\boldsymbol{\\beta})))\n",
    "$$\n",
    "\n",
    "Thus the gradient is\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\boldsymbol{\\beta}} = [\\sigma(\\mathbf{x}\\boldsymbol{\\beta}-y)]\\mathbf{x}\n",
    "$$\n",
    "\n",
    "And then follow the algorithm in the **Gradient Descent** section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Illustration\n",
    "\n",
    "Basicly, rather than using a line to regress numeric values, logistic regression turns a linear regression to a *sigmoid* curve to classify different classes (we use value of y to differentiate classes)\n",
    " \n",
    "<img src=\"images/logistic_regression_illustration.webp\" alt=\"drawing\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros and Cons of Logistic Regression\n",
    "#### Pros\n",
    "- Easier to implement, interpret, and very efficient to train.\n",
    "- Running fast\n",
    "- No assumptions about distributions of classes in feature space.\n",
    "- Can use coefficients to interpret feature importance\n",
    "- Can deal with missing data and no need of normalization.\n",
    "- Easy to interprete feature importance\n",
    "\n",
    "#### Cons\n",
    "- Assume linear relations\n",
    "- Cannot deal with the situation that number of features is larger than number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Code of Logistic Regression <a class=\"anchor\" id=\"Code\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import necessary packages\n",
    "- [pandas](https://pandas.pydata.org/)\n",
    "- [numpy](https://numpy.org/)\n",
    "- [matplotlib](https://matplotlib.org/)\n",
    "- [sklearn](https://scikit-learn.org/stable/datasets/toy_dataset.html)\n",
    "- [seaborn](https://seaborn.pydata.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gradient_descent_Logit_R():\n",
    "    # initialize\n",
    "    def __init__(self) -> None:\n",
    "        self.X = None\n",
    "        self.variables = None\n",
    "        self.y = None\n",
    "        self.predictor = None\n",
    "        self.n = None\n",
    "        self.p = None\n",
    "        self.bias = None\n",
    "        self.gamma = None\n",
    "        self.max_iter = None\n",
    "        self.eta = None\n",
    "\n",
    "        self.weights = None\n",
    "        self.weights_history = []\n",
    "        self.loss_history = [np.inf]\n",
    "    \n",
    "    # cross entropy loss of one data\n",
    "    def cross_entropy_loss(self, y, y_hat):\n",
    "        return -y*np.log(y_hat) - (1.0-y)*np.log(1.0-y_hat)\n",
    "\n",
    "    # total cross entropy loss\n",
    "    def loss(self):\n",
    "        total_loss = sum(self.cross_entropy_loss(self.y[i], self.sigmoid(x@self.weights)) for i, x in enumerate(self.X))\n",
    "        return total_loss\n",
    "\n",
    "    # sigmoid function\n",
    "    def sigmoid(self, z):\n",
    "        return 1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "    # gradient of loss\n",
    "    def gradient_L(self):\n",
    "        sigmoids = np.array([self.sigmoid(x@self.weights) - self.y[i] for i, x in enumerate(self.X)])\n",
    "        d_w = sigmoids @ self.X\n",
    "        return d_w\n",
    "\n",
    "    # model fitting\n",
    "    def fit(self, X, y, bias=True, gamma=0.01, max_iter=100, eta=0.001):\n",
    "        self.variables = X.columns\n",
    "        self.predictor = y.name\n",
    "        \n",
    "        X = X.to_numpy()\n",
    "        y = y.to_numpy()\n",
    "        if bias:\n",
    "            ones_column = np.ones((X.shape[0], 1))\n",
    "            X = np.append(ones_column, X, axis=1)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n = X.shape[0]\n",
    "        self.p = X.shape[1]\n",
    "        self.bias = bias\n",
    "        self.gamma = gamma\n",
    "        self.max_iter = max_iter\n",
    "        self.eta = eta\n",
    "        \n",
    "        weights = np.random.rand(self.p)\n",
    "        self.weights = weights\n",
    "        self.weights_history.append(weights)\n",
    "        for i in range(1, max_iter+1):\n",
    "            dw = self.gradient_L()\n",
    "            weights = weights - gamma * dw\n",
    "            self.weights = weights\n",
    "            self.weights_history.append(weights)\n",
    "            L = self.loss()\n",
    "            self.loss_history.append(L)\n",
    "            if i >= self.max_iter or abs(L - self.loss_history[i-1]) <= self.eta:\n",
    "                break\n",
    "    \n",
    "    # predict new data\n",
    "    def prediction(self, X, weights):\n",
    "        X = X.to_numpy()\n",
    "        if self.bias:\n",
    "            ones_column = np.ones((X.shape[0], 1))\n",
    "            X = np.append(ones_column, X, axis=1)\n",
    "        labels = np.array([1, 0])\n",
    "        y_hat = [self.sigmoid(x @ weights) for x in X]\n",
    "        return [np.random.choice(labels, p = [y_hat_i, 1.0-y_hat_i]) for y_hat_i in y_hat]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Applications on data sets <a class=\"anchor\" id=\"Applications\"></a>\n",
    "\n",
    "* *wine* data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test decistion tree on the *wine* data set from *sklearn.datasets*\n",
    "\n",
    "Load *wine* data, and only pick first 2 types of wines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_wine(return_X_y=True, as_frame=True)\n",
    "X = X[y!=2]\n",
    "y = y[y!=2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the input to avoid dividing by $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.452455</td>\n",
       "      <td>-0.294414</td>\n",
       "      <td>0.302478</td>\n",
       "      <td>-0.940375</td>\n",
       "      <td>1.768686</td>\n",
       "      <td>0.510421</td>\n",
       "      <td>0.775592</td>\n",
       "      <td>-0.462247</td>\n",
       "      <td>1.000229</td>\n",
       "      <td>0.892384</td>\n",
       "      <td>-0.112428</td>\n",
       "      <td>2.040025</td>\n",
       "      <td>0.782868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.289066</td>\n",
       "      <td>-0.214558</td>\n",
       "      <td>-0.677197</td>\n",
       "      <td>-2.239324</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.234327</td>\n",
       "      <td>0.367386</td>\n",
       "      <td>-0.646296</td>\n",
       "      <td>-0.878867</td>\n",
       "      <td>0.114374</td>\n",
       "      <td>-0.052918</td>\n",
       "      <td>0.941437</td>\n",
       "      <td>0.740152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.243886</td>\n",
       "      <td>0.447106</td>\n",
       "      <td>1.113242</td>\n",
       "      <td>-0.054728</td>\n",
       "      <td>0.071792</td>\n",
       "      <td>0.510421</td>\n",
       "      <td>1.020516</td>\n",
       "      <td>-0.278198</td>\n",
       "      <td>1.967684</td>\n",
       "      <td>0.917082</td>\n",
       "      <td>-0.171937</td>\n",
       "      <td>0.455524</td>\n",
       "      <td>1.124598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.610586</td>\n",
       "      <td>-0.020622</td>\n",
       "      <td>0.538951</td>\n",
       "      <td>-0.586117</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>2.443085</td>\n",
       "      <td>1.360688</td>\n",
       "      <td>-0.830346</td>\n",
       "      <td>0.795575</td>\n",
       "      <td>2.226115</td>\n",
       "      <td>-1.183603</td>\n",
       "      <td>1.047071</td>\n",
       "      <td>1.964684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.334246</td>\n",
       "      <td>0.709490</td>\n",
       "      <td>1.788880</td>\n",
       "      <td>0.653789</td>\n",
       "      <td>1.181300</td>\n",
       "      <td>0.510421</td>\n",
       "      <td>0.272138</td>\n",
       "      <td>0.550024</td>\n",
       "      <td>0.125798</td>\n",
       "      <td>0.077326</td>\n",
       "      <td>-0.112428</td>\n",
       "      <td>-0.051517</td>\n",
       "      <td>-0.156889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  1.452455 -0.294414  0.302478 -0.940375  1.768686  0.510421  0.775592   \n",
       "1  0.289066 -0.214558 -0.677197 -2.239324  0.006527  0.234327  0.367386   \n",
       "2  0.243886  0.447106  1.113242 -0.054728  0.071792  0.510421  1.020516   \n",
       "3  1.610586 -0.020622  0.538951 -0.586117  0.854974  2.443085  1.360688   \n",
       "4  0.334246  0.709490  1.788880  0.653789  1.181300  0.510421  0.272138   \n",
       "\n",
       "         7         8         9         10        11        12  \n",
       "0 -0.462247  1.000229  0.892384 -0.112428  2.040025  0.782868  \n",
       "1 -0.646296 -0.878867  0.114374 -0.052918  0.941437  0.740152  \n",
       "2 -0.278198  1.967684  0.917082 -0.171937  0.455524  1.124598  \n",
       "3 -0.830346  0.795575  2.226115 -1.183603  1.047071  1.964684  \n",
       "4  0.550024  0.125798  0.077326 -0.112428 -0.051517 -0.156889  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(X_scaler.fit_transform(X))\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data set and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=24)\n",
    "model = gradient_descent_Logit_R()\n",
    "model.fit(X_train, y_train,gamma=0.01, max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.loss_history)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test data, and check the accuracy and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression, accuracy score = 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.prediction(X_test, model.weights)\n",
    "print(f'Logistic regression, accuracy score = {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "matrix_df = pd.DataFrame(confusion_matrix)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "ax=plt.axes()\n",
    "sns.set(font_scale=1.3)\n",
    "\n",
    "sns.heatmap(matrix_df, annot=True, fmt='g', ax=ax, cmap='magma')\n",
    "ax.set_title('Confusion Matrix of Ensemble Model')\n",
    "ax.set_xlabel('predicted label', fontsize=10)\n",
    "ax.set_ylabel('True label', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A really excellent prediction accuracy! All test data are correctly classified."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
