{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# PCA and K-Means Clustering\n",
    "\n",
    "## Contents\n",
    "- Introduction\n",
    "- Algorithm\n",
    "    - PCA\n",
    "    - K-Means Clustering\n",
    "- Illustration\n",
    "- Pros and Cons\n",
    "- Code and application\n",
    "\n",
    "## Introduction\n",
    "- **Principal Component Analysis (PCA)**, is a dimensionality-reduction method that is often used to reduce the dimensionality of large data sets. The kept dimensions still contain the most variance (information) of features.\n",
    "\n",
    "- **K-Means Clustering** is the algorithm that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean.\n",
    "\n",
    "## Algorithm\n",
    "### PCA\n",
    "The principal components of a collection of points in a real coordinate space are a sequence of $p$ unit vectors, where the $i$-th vector is the direction of a line that best fits the data while being orthogonal to the first $i-1$ vectors. Here, a best-fitting line is defined as one that minimizes the average squared perpendicular distance from the points to the line. These directions constitute an orthonormal basis in which different individual dimensions of the data are linearly uncorrelated. Principal component analysis (PCA) is the process of computing the principal components and using them to perform a change of basis on the data, sometimes using only the first few principal components and ignoring the rest.\n",
    "\n",
    "Consider an $n*p$ data matrix $X$, with column-wise zero empirical mean (the sample mean of each column has been shifted to zero), where each of the n rows represents a different repetition of the experiment, and each of the p columns gives a particular kind of feature (say, the results from a particular sensor).\n",
    "\n",
    "The $k$-th component can be found by subtracting the first $k$ principal components from $X$:\n",
    "$$\\hat{X_{k}}= X - \\sum_{s=1}^{k-1}Xw_{(s)}w^{T}_{(s)} $$\n",
    "and the wieght matrix which extracs the maximum variance from the new data martix\n",
    "$$w_{(k)} = \\argmax_{||X||=1}{||\\hat{X_k}w||^2} = \\argmax{\\frac{w^T\\hat{X_k}^T\\hat{X_k}w}{w^Tw}} $$\n",
    "\n",
    "The full principal components decomposition of X is given by \n",
    "$$ T = XW $$\n",
    "\n",
    "### K-Means Clustering\n",
    "- K-Means Clustering is the algorithm that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean.\n",
    "\n",
    "Given a set of observation $(x_1,x_2,...x_n)$, where each where each observation is a d-dimensional real vector, k-means clustering aims to partition the n observations into k (â‰¤ n) sets $\\textbf{S} ={S_1,S_2,...S_k}$ so as to mminimize the within-cluster sum of squares (WCSS) (i.e. variance). Formally, the objective is to find:\n",
    "$$\n",
    "\\argmin_{\\textbf{S}}\\sum_{i=1}^{k}\\sum_{X \\in S_i}||X-u_i||^2  = \\argmin_{\\textbf{s}}\\sum_{i=1}^{k}|S_i|Var(S_i)\n",
    "$$\n",
    "where $u_i$ is the mean of points in $S_i$. This is equivalent to minimizing the pairwise squared deviation of points in the same cluster:\n",
    "$$\n",
    "\\argmin_{\\textbf{S}}\\sum_{i=1}^{k}\\frac{1}{|S_i|}\\sum_{\\textbf{x,y}\\in S_i}||\\textbf{x-y}||^2\n",
    "$$\n",
    "The equivalence can be deduced from identity $ |S_i| \\sum_{X \\in S_i}||x-u_i||^2 = \\sum_{x \\neq y \\in S_i}{||x-y||^2} $. Since the total variance is constant, this is equivalent to maximizing the sum of squared deviations between points in different clusters (between-cluster sum of squares, BCSS),.[1] This deterministic relationship is also related to the law of total variance in probability theory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
